{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB0ZYLU8FbZ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGyXIW2SFom_"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'comsci125teerapong'\n",
        "os.environ['KAGGLE_KEY'] = 'c4095229aa2a02465c0b05b9152063c6'\n",
        "\n",
        "!pip install kaggle\n",
        "!kaggle competitions download -c super-ai-engineer-2021-house-grade-classification\n",
        "\n",
        "# datasets.utils.extract_archive('/content/super-ai-engineer-2021-house-grade-classification.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWPhHRdZBSs5"
      },
      "outputs": [],
      "source": [
        "!unzip /content/super-ai-engineer-2021-house-grade-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDPOyZZ9B5QF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "address_df = pd.read_csv('/content/train.csv')\n",
        "address_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSotVjJaFVQ_"
      },
      "outputs": [],
      "source": [
        "address_df.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afize-4oUwT3"
      },
      "outputs": [],
      "source": [
        "class_train = pd.concat([\n",
        "  address_df[ address_df['class']==0].sample(n=1500,replace=True, random_state=1),\n",
        "  address_df[ address_df['class']==1].sample(n=1000,replace=True, random_state=1),\n",
        "  address_df[ address_df['class']==2].sample(n=1000,replace=True, random_state=1),\n",
        "  address_df[ address_df['class']==3].sample(n=1000,replace=True, random_state=1),\n",
        "  address_df[ address_df['class']==4].sample(n=1000,replace=True, random_state=1),\n",
        "  address_df[ address_df['class']==5].sample(n=1000,replace=True, random_state=1),\n",
        "  ],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_train.hist()"
      ],
      "metadata": {
        "id": "T6-Oes2NT9qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvesPFMDVLuc"
      },
      "outputs": [],
      "source": [
        "class_train = pd.DataFrame(class_train)\n",
        "class_train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2X6MChAc0Rt"
      },
      "outputs": [],
      "source": [
        "class_train.rename(\n",
        "    columns={\"class\":\"Class\",}\n",
        "          ,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD_tQ1zQc-vr"
      },
      "outputs": [],
      "source": [
        "class_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgmn8c4mcMOu"
      },
      "outputs": [],
      "source": [
        "name_img = class_train.image_name.tolist()\n",
        "name_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhw77pWScnLD"
      },
      "outputs": [],
      "source": [
        "class_img = class_train.Class.tolist()\n",
        "class_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QknTUJlMgKHb"
      },
      "outputs": [],
      "source": [
        "class_img.count(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwqtROFMem7T"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/data'\n",
        "!mkdir '/content/data/train'\n",
        "!mkdir '/content/data/train/0'\n",
        "!mkdir '/content/data/train/1'\n",
        "!mkdir '/content/data/train/2'\n",
        "!mkdir '/content/data/train/3'\n",
        "!mkdir '/content/data/train/4'\n",
        "!mkdir '/content/data/train/5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbjrGF5VX2fJ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image \n",
        "import PIL  \n",
        "dir = '/content/train/'\n",
        "x = 0\n",
        "for i in range(6500):\n",
        "  if class_img[i] == 0:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/0/{class_img[i]}_{i}.jpg\")\n",
        "  if class_img[i] == 1:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/1/{class_img[i]}_{i}.jpg\")\n",
        "  if class_img[i] == 2:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/2/{class_img[i]}_{i}.jpg\") \n",
        "  if class_img[i] == 3:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/3/{class_img[i]}_{i}.jpg\")\n",
        "  if class_img[i] == 4:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/4/{class_img[i]}_{i}.jpg\") \n",
        "  if class_img[i] == 5:\n",
        "    picture = Image.open(dir+name_img[i])\n",
        "    picture = picture.convert('RGB')\n",
        "    picture.save(f\"/content/data/train/5/{class_img[i]}_{i}.jpg\")    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/train"
      ],
      "metadata": {
        "id": "HJM7bcilB9co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Nr83dOgjKl"
      },
      "outputs": [],
      "source": [
        "import os, random, cv2\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import tensorflow.keras.backend as K \n",
        "import tensorflow as tf; print(tf.__version__)\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow import keras \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.random import rand \n",
        "import matplotlib.cm as cm\n",
        "import numpy as np \n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try: \n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "except: \n",
        "    pass \n",
        "\n",
        "seed = 786\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snco3LUdrg6Z"
      },
      "outputs": [],
      "source": [
        "# import pathlib\n",
        "\n",
        "# dataset_url = \"https://drive.google.com/file/d/1-8OXLkK7Hpq917cwvIRUKUhtxYZf-2Ua/view?usp=sharing\"\n",
        "# data_dir = tf.keras.utils.get_file('train', origin=dataset_url, untar=True)\n",
        "# data_dir = pathlib.Path(data_dir)\n",
        "# print(data_dir)\n",
        "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "# print('Total Samples: ', image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crDR-BQAgjCB"
      },
      "outputs": [],
      "source": [
        "epochs       = 7 \n",
        "img_size     = 384\n",
        "batch_size   = 32\n",
        "class_number = 6\n",
        "use_cut_mix  = True\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/data/train',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(384, 384))\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory='/content/data/train',\n",
        "    label_mode='categorical',\n",
        "    batch_size=32,\n",
        "    image_size=(384, 384))\n",
        "\n",
        "tcls_names, vcls_names = train_ds.class_names , validation_ds.class_names\n",
        "tcls_names, vcls_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS4uPWawhsOq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(images.shape, labels.shape)\n",
        "    \n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        # plt.title(tcls_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lAApT1oqgt7"
      },
      "outputs": [],
      "source": [
        "class MixUp(layers.Layer):\n",
        "\n",
        "    def __init__(self, num_classes, batch_size, mixup_prob=0.88, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.prob = mixup_prob \n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "    \n",
        "    def call(self, batch_inputs, training=None):\n",
        "        bs_images = batch_inputs[0] # ALL Image Samples \n",
        "        bs_labels = batch_inputs[1] # ALL Lable Samples \n",
        "        \n",
        "        # Meta info \n",
        "        _, height, width, channel = bs_images.get_shape().as_list()\n",
        "        mixup_images = []; mixup_labels = []\n",
        "    \n",
        "        for j in range(self.batch_size):\n",
        "            # Choose Random Image to MixUp with\n",
        "            k = tf.cast( tf.random.uniform([], 0, tf.cast(self.batch_size, tf.float32)), tf.int32)\n",
        "\n",
        "            # Do MixUp with PROBABILITY Defined Above\n",
        "            p = tf.cast( tf.random.uniform([], 0, 1) <= self.prob, tf.float32)\n",
        "\n",
        "            # It's beta dist with alpha=1.0\n",
        "            a = tf.random.uniform([], 0, 1)*p\n",
        "\n",
        "            # Do MixUp 2 Images \n",
        "            img_x = bs_images[j]\n",
        "            img_y = bs_images[k]\n",
        "            mixup_images.append( (1-a) * img_x + a * img_y )\n",
        "\n",
        "            # Do MixUp 2 Labels \n",
        "            if len(bs_labels.shape) == 1:\n",
        "                lbs_x = tf.one_hot(bs_labels[j], self.num_classes)\n",
        "                lbs_y = tf.one_hot(bs_labels[k], self.num_classes)\n",
        "            else:\n",
        "                lbs_x = bs_labels[j]\n",
        "                lbs_y = bs_labels[k]\n",
        "                \n",
        "            lbs_x = tf.cast(lbs_x, tf.float32)\n",
        "            lbs_y = tf.cast(lbs_y, tf.float32)\n",
        "            mixup_labels.append( (1-a) * lbs_x + a * lbs_y )\n",
        "\n",
        "        # Reshape \n",
        "        mixup_images = tf.reshape(tf.stack(mixup_images), (-1, height, width, channel))\n",
        "        mixup_labels = tf.reshape(tf.stack(mixup_labels), (-1, self.num_classes))\n",
        "        return [mixup_images, mixup_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Aa3PBnqldr"
      },
      "outputs": [],
      "source": [
        "class CutMix(layers.Layer):\n",
        "\n",
        "    def __init__(self, num_classes, batch_size, cutmix_prob=0.88, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.prob = cutmix_prob \n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "    def call(self, batch_inputs, training=None):\n",
        "        bs_images = batch_inputs[0] # ALL Image Samples \n",
        "        bs_labels = batch_inputs[1] # ALL Lable Samples \n",
        "        # Meta info \n",
        "        _, height, width, channel = bs_images.get_shape().as_list()\n",
        "        img_size = height # TO DO: Support Non-Square Image \n",
        "        cutmix_images = []; cutmix_labels = []\n",
        "\n",
        "        for j in range(self.batch_size):\n",
        "            # Do CutMix with PROBABILITY Defined Above\n",
        "            p = tf.cast( tf.random.uniform([],0, 1) <= self.prob, tf.int32)\n",
        "\n",
        "            # Choose Random Image to CutMix with\n",
        "            k = tf.cast( tf.random.uniform([], 0, self.batch_size), tf.int32)\n",
        "\n",
        "            # Choose Random Location \n",
        "            x = tf.cast( tf.random.uniform([],0, img_size),tf.int32)\n",
        "            y = tf.cast( tf.random.uniform([],0, img_size),tf.int32)\n",
        "\n",
        "            # It's beta dist with alpha=1.0\n",
        "            b = tf.random.uniform([], 0, 1) \n",
        "\n",
        "            w = tf.cast(img_size * tf.math.sqrt(1-b), tf.int32) * p\n",
        "            ya = tf.math.maximum(0,   y-w//2)\n",
        "            yb = tf.math.minimum(img_size, y+w//2)\n",
        "            xa = tf.math.maximum(0,   x-w//2)\n",
        "            xb = tf.math.minimum(img_size, x+w//2)\n",
        "\n",
        "            # Do CutMix \n",
        "            one    = bs_images[j, ya:yb, 0:xa,        :]\n",
        "            two    = bs_images[k, ya:yb, xa:xb,       :]\n",
        "            three  = bs_images[j, ya:yb, xb:img_size, :]\n",
        "            middle = tf.concat([one, two, three], axis=1)\n",
        "            img    = tf.concat([bs_images[j, 0:ya, :, :],\n",
        "                                middle,\n",
        "                                bs_images[j, yb:img_size, :, :]], axis=0)\n",
        "            cutmix_images.append(img)\n",
        "\n",
        "            # MAKE CUTMIX LABEL\n",
        "            a = tf.cast(w * w / img_size / img_size, tf.float32)\n",
        "            if len(bs_labels.shape) == 1:\n",
        "                lab1 = tf.one_hot(bs_labels[j], self.num_classes)\n",
        "                lab2 = tf.one_hot(bs_labels[k], self.num_classes)\n",
        "            else:\n",
        "                lab1 = bs_labels[j]\n",
        "                lab2 = bs_labels[k]\n",
        "\n",
        "            cutmix_labels.append((1-a)*lab1 + a*lab2)\n",
        "\n",
        "        # Reshape \n",
        "        cutmix_images = tf.reshape(tf.stack(cutmix_images), (-1, height, width, channel))\n",
        "        cutmix_labels = tf.reshape(tf.stack(cutmix_labels), (-1, self.num_classes))\n",
        "        return [cutmix_images, cutmix_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3QYeqwrqsl8"
      },
      "outputs": [],
      "source": [
        "class RandomMixUpCutMix(layers.Layer):\n",
        "    def __init__(self, num_classes, batch_size, switch_prob=0.10, mixup_prob=0.1, cutmix_prob=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mixup_prob = mixup_prob   # mixup probability \n",
        "        self.cutmix_prob = cutmix_prob # cutmix probability \n",
        "        self.switch_prob = switch_prob # probability of switching between mixup and cutmix \n",
        "        self.mixup  = CutMix(num_classes, batch_size=batch_size, cutmix_prob=cutmix_prob)\n",
        "        self.cutmix = MixUp(num_classes, batch_size=batch_size, mixup_prob=mixup_prob)\n",
        "        \n",
        "    def call(self, batch_inputs, training=None):\n",
        "        if training: \n",
        "            bs_images = batch_inputs[0] # ALL Image Samples \n",
        "            bs_labels = batch_inputs[1] # ALL Lable Samples \n",
        "            return tf.cond(\n",
        "                tf.less(\n",
        "                    tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32), \n",
        "                    tf.cast(self.switch_prob, tf.float32)),\n",
        "                    lambda: self.mixup([bs_images, bs_labels]), lambda: self.cutmix([bs_images, bs_labels]))\n",
        "        else:\n",
        "            return batch_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BCO-oK0q1O6"
      },
      "outputs": [],
      "source": [
        "# for train set : augmentation \n",
        "keras_aug = keras.Sequential(\n",
        "     [ \n",
        "          # layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "          layers.RandomZoom(.2, .3)\n",
        "          # layers.Rescaling(1./255),\n",
        "          # layers.RandomRotation((0.1, 0.2), fill_mode=\"reflect\")\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "# train_ds = train_ds.shuffle(10 * batch_size)\n",
        "# train_ds = train_ds.map(lambda x, y: (keras_aug(x), y), num_parallel_calls=AUTOTUNE)\n",
        "# train_ds = train_ds.map(lambda x, y: RandomMixUpCutMix(len(tcls_names), \n",
        "#                                                        batch_size)([x, y], training=True), \n",
        "#                         num_parallel_calls=AUTOTUNE)\n",
        "# train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MerUjj1_rLkN"
      },
      "outputs": [],
      "source": [
        "for images, labels in train_ds.take(5):\n",
        "    print(images.shape, labels.shape)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(labels[i].numpy())\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqTKKnLSrRvi"
      },
      "outputs": [],
      "source": [
        "# def k_hot(x, y): \n",
        "#     return x, tf.one_hot(y, class_number)\n",
        "\n",
        "# val_ds = validation_ds.map(k_hot) if use_cut_mix else val_ds\n",
        "# val_ds = validation_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for images, labels in validation_ds.take(1):\n",
        "    print(images.shape, labels.shape)\n",
        "    for i in range(9):\n",
        "        augmented_images = keras_aug(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint64\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eXtu5NauTr8"
      },
      "outputs": [],
      "source": [
        "patch_size      = (4,4)  # 4-by-4 sized patches\n",
        "dropout_rate    = 0.5     # Dropout rate\n",
        "num_heads       = 16       # Attention heads  #Test 24\n",
        "embed_dim       = 64      # Embedding dimension\n",
        "num_mlp         = 128     # MLP layer size\n",
        "qkv_bias        = True    # Convert embedded patches to query, key, and values with a learnable additive value\n",
        "window_size     = 2       # Size of attention window\n",
        "shift_size      = 1       # Size of shifting window\n",
        "image_dimension = 24      # Initial image size / Input size of the transformer model \n",
        "\n",
        "num_patch_x = image_dimension // patch_size[0]\n",
        "num_patch_y = image_dimension // patch_size[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_X0lYGlucgb"
      },
      "outputs": [],
      "source": [
        "def window_partition(x, window_size):\n",
        "    _, height, width, channels = x.shape\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
        "    )\n",
        "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
        "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
        "    return windows\n",
        "\n",
        "\n",
        "def window_reverse(windows, window_size, height, width, channels):\n",
        "    patch_num_y = height // window_size\n",
        "    patch_num_x = width // window_size\n",
        "    x = tf.reshape(\n",
        "        windows,\n",
        "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
        "    )\n",
        "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
        "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "    return x\n",
        "\n",
        "\n",
        "class DropPath(layers.Layer):\n",
        "    def __init__(self, drop_prob=None, **kwargs):\n",
        "        super(DropPath, self).__init__(**kwargs)\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def call(self, x):\n",
        "        input_shape = tf.shape(x)\n",
        "        batch_size = input_shape[0]\n",
        "        rank = x.shape.rank\n",
        "        shape = (batch_size,) + (1,) * (rank - 1)\n",
        "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
        "        path_mask = tf.floor(random_tensor)\n",
        "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6TvTh8nugHa"
      },
      "outputs": [],
      "source": [
        "class WindowAttention(layers.Layer):\n",
        "    def __init__(\n",
        "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
        "    ):\n",
        "        super(WindowAttention, self).__init__(**kwargs)\n",
        "        self.dim = dim\n",
        "        self.window_size = window_size\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
        "        self.dropout = layers.Dropout(dropout_rate)\n",
        "        self.proj = layers.Dense(dim)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
        "            2 * self.window_size[1] - 1\n",
        "        )\n",
        "        self.relative_position_bias_table = self.add_weight(\n",
        "            shape=(num_window_elements, self.num_heads),\n",
        "            initializer=tf.initializers.Zeros(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        coords_h = np.arange(self.window_size[0])\n",
        "        coords_w = np.arange(self.window_size[1])\n",
        "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
        "        coords = np.stack(coords_matrix)\n",
        "        coords_flatten = coords.reshape(2, -1)\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
        "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
        "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
        "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "\n",
        "        self.relative_position_index = tf.Variable(\n",
        "            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
        "        )\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        _, size, channels = x.shape\n",
        "        head_dim = channels // self.num_heads\n",
        "        x_qkv = self.qkv(x)\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
        "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
        "        q = q * self.scale\n",
        "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
        "        attn = q @ k\n",
        "\n",
        "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
        "        relative_position_index_flat = tf.reshape(\n",
        "            self.relative_position_index, shape=(-1,)\n",
        "        )\n",
        "        relative_position_bias = tf.gather(\n",
        "            self.relative_position_bias_table, relative_position_index_flat\n",
        "        )\n",
        "        relative_position_bias = tf.reshape(\n",
        "            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
        "        )\n",
        "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
        "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.get_shape()[0]\n",
        "            mask_float = tf.cast(\n",
        "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
        "            )\n",
        "            attn = (\n",
        "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
        "                + mask_float\n",
        "            )\n",
        "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        else:\n",
        "            attn = keras.activations.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x_qkv = attn @ v\n",
        "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
        "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
        "        x_qkv = self.proj(x_qkv)\n",
        "        x_qkv = self.dropout(x_qkv)\n",
        "        return x_qkv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbD6kRCRujp8"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        dim,\n",
        "        num_patch,\n",
        "        num_heads,\n",
        "        window_size=7,\n",
        "        shift_size=0,\n",
        "        num_mlp=1024,\n",
        "        qkv_bias=True,\n",
        "        dropout_rate=0.0,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super(SwinTransformer, self).__init__(**kwargs)\n",
        "\n",
        "        self.dim = dim  # number of input dimensions\n",
        "        self.num_patch = num_patch  # number of embedded patches\n",
        "        self.num_heads = num_heads  # number of attention heads\n",
        "        self.window_size = window_size  # size of window\n",
        "        self.shift_size = shift_size  # size of window shift\n",
        "        self.num_mlp = num_mlp  # number of MLP nodes\n",
        "\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.attn = WindowAttention(\n",
        "            dim,\n",
        "            window_size=(self.window_size, self.window_size),\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "        self.drop_path = DropPath(dropout_rate)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.mlp = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(num_mlp),\n",
        "                layers.Activation(keras.activations.gelu),\n",
        "                layers.Dropout(dropout_rate),\n",
        "                layers.Dense(dim),\n",
        "                layers.Dropout(dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if min(self.num_patch) < self.window_size:\n",
        "            self.shift_size = 0\n",
        "            self.window_size = min(self.num_patch)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.shift_size == 0:\n",
        "            self.attn_mask = None\n",
        "        else:\n",
        "            height, width = self.num_patch\n",
        "            h_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            w_slices = (\n",
        "                slice(0, -self.window_size),\n",
        "                slice(-self.window_size, -self.shift_size),\n",
        "                slice(-self.shift_size, None),\n",
        "            )\n",
        "            mask_array = np.zeros((1, height, width, 1))\n",
        "            count = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices:\n",
        "                    mask_array[:, h, w, :] = count\n",
        "                    count += 1\n",
        "            mask_array = tf.convert_to_tensor(mask_array)\n",
        "\n",
        "            # mask array to windows\n",
        "            mask_windows = window_partition(mask_array, self.window_size)\n",
        "            mask_windows = tf.reshape(\n",
        "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
        "            )\n",
        "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
        "                mask_windows, axis=2\n",
        "            )\n",
        "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
        "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
        "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, num_patches_before, channels = x.shape\n",
        "        x_skip = x\n",
        "        x = self.norm1(x)\n",
        "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
        "        if self.shift_size > 0:\n",
        "            shifted_x = tf.roll(\n",
        "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            shifted_x = x\n",
        "\n",
        "        x_windows = window_partition(shifted_x, self.window_size)\n",
        "        x_windows = tf.reshape(\n",
        "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
        "        )\n",
        "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
        "\n",
        "        attn_windows = tf.reshape(\n",
        "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
        "        )\n",
        "        shifted_x = window_reverse(\n",
        "            attn_windows, self.window_size, height, width, channels\n",
        "        )\n",
        "        if self.shift_size > 0:\n",
        "            x = tf.roll(\n",
        "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
        "            )\n",
        "        else:\n",
        "            x = shifted_x\n",
        "\n",
        "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        x_skip = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        x = self.drop_path(x)\n",
        "        x = x_skip + x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9IjVPS4unVy"
      },
      "outputs": [],
      "source": [
        "class PatchExtract(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super(PatchExtract, self).__init__(**kwargs)\n",
        "        self.patch_size_x = patch_size[0]\n",
        "        self.patch_size_y = patch_size[0]\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
        "            rates=(1, 1, 1, 1),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dim = patches.shape[-1]\n",
        "        patch_num = patches.shape[1]\n",
        "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
        "\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
        "        super(PatchEmbedding, self).__init__(**kwargs)\n",
        "        self.num_patch = num_patch\n",
        "        self.proj = layers.Dense(embed_dim)\n",
        "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
        "        return self.proj(patch) + self.pos_embed(pos)\n",
        "\n",
        "\n",
        "class PatchMerging(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_patch, embed_dim):\n",
        "        super(PatchMerging, self).__init__()\n",
        "        self.num_patch = num_patch\n",
        "        self.embed_dim = embed_dim\n",
        "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
        "\n",
        "    def call(self, x):\n",
        "        height, width = self.num_patch\n",
        "        _, _, C = x.get_shape().as_list()\n",
        "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
        "        feat_maps = x\n",
        "     \n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
        "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
        "        return self.linear_trans(x), feat_maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IykBCy8BuqtE"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import Model, Sequential, Input, layers, applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HhSCBh7wl3j"
      },
      "outputs": [],
      "source": [
        "class HybridSwinTransformer(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(HybridSwinTransformer, self).__init__()\n",
        "        # base models \n",
        "        self.inputx = keras.Input((img_size, img_size, 3), name='input_hybrids')\n",
        "        base = applications.EfficientNetB0(\n",
        "            include_top=False,\n",
        "            # weights=BASE_WEIGHTS + ADV_PROB[0],\n",
        "            input_tensor=self.inputx\n",
        "        )\n",
        "        \n",
        "        # base model with compatible output which will be an input of transformer model \n",
        "        self.new_base = keras.Model(\n",
        "            [base.inputs], \n",
        "            [\n",
        "                base.get_layer('block6a_expand_activation').output, \n",
        "                base.output\n",
        "            ], # output with 192 feat_maps\n",
        "            name='efficientnet'\n",
        "        )\n",
        "        \n",
        "        # stuff of swin transformers \n",
        "        self.patch_extract  = PatchExtract(patch_size)\n",
        "        self.patch_embedds  = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)\n",
        "        self.patch_merging  = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)\n",
        "        \n",
        "        # swin blocks containers \n",
        "        self.swin_sequences = keras.Sequential(name='swin_blocks')\n",
        "        for i in range(shift_size):\n",
        "            self.swin_sequences.add(\n",
        "                SwinTransformer(\n",
        "                    dim=embed_dim,\n",
        "                    num_patch=(num_patch_x, num_patch_y),\n",
        "                    num_heads=num_heads,\n",
        "                    window_size=window_size,\n",
        "                    shift_size=i,\n",
        "                    num_mlp=num_mlp,\n",
        "                    qkv_bias=qkv_bias,\n",
        "                    dropout_rate=dropout_rate\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # swin block's head\n",
        "        self.swin_head = keras.Sequential(\n",
        "            [\n",
        "                layers.GlobalAveragePooling1D(),\n",
        "                layers.AlphaDropout(0.5),\n",
        "                layers.BatchNormalization(),\n",
        "            ], name='swin_head'\n",
        "        )\n",
        "        \n",
        "        # base model's (cnn model) head\n",
        "        self.conv_head = keras.Sequential(\n",
        "            [\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "                layers.AlphaDropout(0.5),\n",
        "            ], name='conv_head'\n",
        "        )\n",
        "        \n",
        "        # classifier\n",
        "        self.classifier = layers.Dense(class_number, dtype='float32')\n",
        "        \n",
        "        \n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        x , base_gcam_top = self.new_base(inputs)\n",
        "        x = self.patch_extract(x)\n",
        "        x = self.patch_embedds(x)\n",
        "        x = self.swin_sequences(x)\n",
        "        x, swin_gcam_top = self.patch_merging(x)\n",
        "        \n",
        "        swin_top = self.swin_head(x)\n",
        "        conv_top = self.conv_head(base_gcam_top)\n",
        "        preds = self.classifier(tf.concat([swin_top, conv_top], axis=-1))\n",
        "        \n",
        "        if training: # training phase \n",
        "            return preds\n",
        "        else: # inference phase\n",
        "            return preds, base_gcam_top, swin_gcam_top\n",
        "\n",
        "    def build_graph(self):\n",
        "        x = keras.Input(shape=(img_size, img_size, 3))\n",
        "        return keras.Model(inputs=[x], outputs=self.call(x))\n",
        "    \n",
        "keras.backend.clear_session()\n",
        "model = HybridSwinTransformer()\n",
        "print(model(tf.ones((2, img_size, img_size, 3)))[0].shape)\n",
        "display(keras.utils.plot_model(model.build_graph(), \n",
        "                               show_shapes=True,\n",
        "                               show_layer_names=True, \n",
        "                               expand_nested=False))\n",
        "model.build_graph().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGajjzgWxQNr"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezu7VM8VwpsJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import losses, optimizers , metrics\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow_addons import optimizers as tfa_optimizers\n",
        "\n",
        "rlr = callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.3, patience=2)\n",
        "ckp = callbacks.ModelCheckpoint('model.h5', \n",
        "                                monitor=\"val_accuracy\", \n",
        "                                verbose=1,\n",
        "                                save_best_only=True, \n",
        "                                save_weights_only=True,\n",
        "                                mode=\"max\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1z_5Da4xUfN"
      },
      "outputs": [],
      "source": [
        "# compile and run \n",
        "if use_cut_mix:\n",
        "    loss_fn = losses.CategoricalCrossentropy(label_smoothing = 0.01, from_logits=True) \n",
        "else:\n",
        "    loss_fn = losses.SparseCategoricalCrossentropy(from_logits=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQvL-WglxW_e"
      },
      "outputs": [],
      "source": [
        "# compile and run\n",
        "model.compile(\n",
        "    loss=loss_fn,\n",
        "    optimizer=tfa_optimizers.AdamW(learning_rate=1e-4, weight_decay=0.00001), \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ISSUE: ValueError: Unable to create dataset (name already exists)\n",
        "# [ugly workaround!]\n",
        "for i in range(len(model.weights)):\n",
        "    model.weights[i]._handle_name = model.weights[i].name +  str(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training \n",
        "history = model.fit(train_ds, \n",
        "                    epochs=12,\n",
        "                    callbacks=[ckp, rlr], \n",
        "                    validation_data=validation_ds, \n",
        "                    verbose=0)"
      ],
      "metadata": {
        "id": "_mPbaJW8kgl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYm4Wif3zTYT"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "from tensorflow.keras import datasets , layers , models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvUp0UOh3kV8"
      },
      "outputs": [],
      "source": [
        "img = cv.imread('/content/test/3cb7e6f8.jpg')\n",
        "imgre = cv.resize(img,(384,384))\n",
        "imgre = cv.cvtColor(imgre, cv.COLOR_RGB2BGR)\n",
        "img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "\n",
        "preds, base_top, swin_top = model.predict(np.array([imgre]))\n",
        "pred_index = tf.argmax(preds[0])\n",
        "pred_index.numpy()\n",
        "# index = np.argmax(predict[0])\n",
        "# classname = class_name[index]\n",
        "\n",
        "cv.putText(img, f'{pred_index}', (20, 30), cv.FONT_HERSHEY_PLAIN, 2, (0,0,255),2)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9U8D3mWbwmqu"
      },
      "outputs": [],
      "source": [
        "submiss_name = pd.read_csv('/content/sample_submission.csv')\n",
        "submiss_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay97uKqRxKFe"
      },
      "outputs": [],
      "source": [
        "name_id = submiss_name['Id']\n",
        "name_id = pd.DataFrame(name_id)\n",
        "name_id = name_id.values.tolist()\n",
        "name_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsFwcpQU9Nya"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "image_list = []\n",
        "predict_list = []\n",
        "x = 1 \n",
        "# glob.glob('/content/test/*.jpg'): #assuming gif\n",
        "\n",
        "for i in range(1550):\n",
        "      filename = '/content/test/'+ name_id[i][0] + \".jpg\"\n",
        "      img = cv.imread(filename)\n",
        "      if img is not None:\n",
        "        x = x+1\n",
        "        imgre = cv.resize(img,(384,384))\n",
        "        imgre = cv.cvtColor(imgre, cv.COLOR_RGB2BGR)\n",
        "      # img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "\n",
        "        preds, base_top, swin_top = model.predict(np.array([imgre]))\n",
        "        pred_index = tf.argmax(preds[0])\n",
        "        predict_list.append(pred_index.numpy())\n",
        "      else:\n",
        "        predict_list.append(0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuNr_jr725HE"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JFSm6xfBp9x"
      },
      "outputs": [],
      "source": [
        "len(predict_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSlupjdPDGe6"
      },
      "outputs": [],
      "source": [
        "x = np.reshape(predict_list,(1,1550)).T\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_BcjJRfBtQa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_class = pd.DataFrame(x)\n",
        "df_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8mRlWhk3jpM"
      },
      "outputs": [],
      "source": [
        "len(name_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A5psn5GDkZO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_id = pd.DataFrame(name_id)\n",
        "df_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puHrMnygDpGg"
      },
      "outputs": [],
      "source": [
        "data_pred = pd.concat([df_id, df_class], axis=1)\n",
        "\n",
        "data_pred.columns = ['Id', 'Predicted']\n",
        "data_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_ueH7GDFzxa"
      },
      "outputs": [],
      "source": [
        "data_pred.to_csv('predict_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p5lqE1sHfgng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model.h5 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "5Eqx3GC9fP0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPFBUs5A5-Fj"
      },
      "outputs": [],
      "source": [
        "##############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVBTgSxG6AT2"
      },
      "outputs": [],
      "source": [
        "def plot_stuff(inputs, features_a, features_b):\n",
        "    plt.figure(figsize=(25, 25))\n",
        "    \n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(tf.squeeze(inputs/255, axis=0))\n",
        "    plt.title('Input')\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(features_a)\n",
        "    plt.title('CNN')\n",
        "    \n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(features_b)\n",
        "    plt.title('Hybrid-CNN-Transformer')\n",
        "    plt.show()\n",
        "\n",
        "# ref: https://keras.io/examples/vision/grad_cam/\n",
        "def get_img_array(img):\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "# ref: https://keras.io/examples/vision/grad_cam/\n",
        "def make_gradcam_heatmap(img_array, grad_model, pred_index=None):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        preds, base_top, swin_top = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "        \n",
        "    grads = tape.gradient(class_channel, base_top)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    base_top = base_top[0]\n",
        "    heatmap_a = base_top @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap_a = tf.squeeze(heatmap_a)\n",
        "    heatmap_a = tf.maximum(heatmap_a, 0) / tf.math.reduce_max(heatmap_a)\n",
        "    heatmap_a = heatmap_a.numpy()\n",
        "    \n",
        "    grads = tape.gradient(class_channel, swin_top)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    swin_top = swin_top[0]\n",
        "    heatmap_b = swin_top @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap_b = tf.squeeze(heatmap_b)\n",
        "    heatmap_b = tf.maximum(heatmap_b, 0) / tf.math.reduce_max(heatmap_b)\n",
        "    heatmap_b = heatmap_b.numpy()\n",
        "    return heatmap_a, heatmap_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_oCqaji6BXj"
      },
      "outputs": [],
      "source": [
        "# load save weight\n",
        "model.load_weights('/content/model.h5')\n",
        "\n",
        "# Prepare image\n",
        "img_arrays = next(iter(validation_ds))[0]; print(img_arrays.shape)\n",
        "\n",
        "# plot utils\n",
        "for img_array in img_arrays:\n",
        "    # Generate class activation heatmap\n",
        "    img_array = get_img_array(img_array)\n",
        "    cnn_heatmap, swin_heatmap = make_gradcam_heatmap(img_array, model) \n",
        "    print(cnn_heatmap.shape, cnn_heatmap.max(), cnn_heatmap.min())\n",
        "    print(swin_heatmap.shape, swin_heatmap.max(), swin_heatmap.min())\n",
        "    \n",
        "    # Display heatmap\n",
        "    plot_stuff(img_array, cnn_heatmap, swin_heatmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1q4_7z26Swq"
      },
      "outputs": [],
      "source": [
        "# ref: https://keras.io/examples/vision/grad_cam/\n",
        "def save_and_display_gradcam(img, \n",
        "                             heatmap, \n",
        "                             target=None, \n",
        "                             pred=None,\n",
        "                             cam_path=\"cam.jpg\",  \n",
        "                             alpha=0.6, \n",
        "                             plot=None):\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\") \n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors  = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[0], img.shape[1]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = img + jet_heatmap * alpha\n",
        "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "    return superimposed_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqDIgr606Xhq"
      },
      "outputs": [],
      "source": [
        "samples, labels = next(iter(validation_ds))\n",
        "\n",
        "for sample, label in zip(samples, labels):\n",
        "    # preparing \n",
        "    img_array = sample[tf.newaxis, ...] \n",
        "    \n",
        "    # get heatmaps \n",
        "    heatmap_a, heatmap_b = make_gradcam_heatmap(img_array, model)\n",
        "    \n",
        "    # overaly heatmap and input sample \n",
        "    overaly_a = save_and_display_gradcam(sample, heatmap_a)\n",
        "    overlay_b = save_and_display_gradcam(sample, heatmap_b)\n",
        "    \n",
        "    # ploting stuff \n",
        "    plot_stuff(img_array, overaly_a, overlay_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQkHoNQR6dba"
      },
      "outputs": [],
      "source": [
        "!cp /content/model.h5 /content/drive/MyDrive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################### Test  Model Load Weight  ############################"
      ],
      "metadata": {
        "id": "FBWEiiqfGRZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/model.h5')\n",
        "\n",
        "img = cv.imread('/content/test/3cb7e6f8.jpg')\n",
        "imgre = cv.resize(img,(384,384))\n",
        "imgre = cv.cvtColor(imgre, cv.COLOR_RGB2BGR)\n",
        "img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
        "\n",
        "preds, base_top, swin_top = model.predict(np.array([imgre]))\n",
        "pred_index = tf.argmax(preds[0])\n",
        "pred_index.numpy()\n",
        "# index = np.argmax(predict[0])\n",
        "# classname = class_name[index]\n",
        "\n",
        "cv.putText(img, f'{pred_index}', (20, 30), cv.FONT_HERSHEY_PLAIN, 2, (0,0,255),2)\n",
        "plt.imshow(img)\n"
      ],
      "metadata": {
        "id": "pyPTShkZGBzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE8OB_rEgi5i"
      },
      "outputs": [],
      "source": [
        "##############################################################################3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Efficient_large_scale_&_Hybrid_Swin_Transformers_&_GradCamV2.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}