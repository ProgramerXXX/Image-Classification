{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CJ9_5r5qE8f",
        "outputId": "bec40bed-3f81-4892-f191-1a5b19f8df0f"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "from yolov5 import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.0-126-g3f152e5 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFc48-1gqPXz"
      },
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "wXbkeiZVqQ9D",
        "outputId": "2dd89962-6005-4fd0-f952-2a23c3526446"
      },
      "source": [
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MQmSHm3qWGf",
        "outputId": "578b23c0-890d-4217-8691-1f2245f520d0"
      },
      "source": [
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/data/'\n",
        "annotations_path = path + 'annotations/'\n",
        "images_path = path + 'images/'\n",
        "\n",
        "annotations_files = [something for something in os.listdir(annotations_path) if not os.path.isdir(annotations_path + something)]\n",
        "images_files = [something for something in os.listdir(images_path) if not os.path.isdir(images_path + something)]\n",
        "annotations_files[:5], images_files[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['maksssksksss1.xml',\n",
              "  'maksssksksss104.xml',\n",
              "  'maksssksksss106.xml',\n",
              "  'maksssksksss103.xml',\n",
              "  'maksssksksss101.xml'],\n",
              " ['maksssksksss0.png',\n",
              "  'maksssksksss1.png',\n",
              "  'maksssksksss13.png',\n",
              "  'maksssksksss116.png',\n",
              "  'maksssksksss137.png'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDM-4eEVq6DT",
        "outputId": "faaf937a-6e56-49c6-85ce-54125976b851"
      },
      "source": [
        "import re\n",
        "\n",
        "annotations_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\n",
        "images_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\n",
        "annotations_files[:5], images_files[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['maksssksksss0.xml',\n",
              "  'maksssksksss1.xml',\n",
              "  'maksssksksss2.xml',\n",
              "  'maksssksksss3.xml',\n",
              "  'maksssksksss4.xml'],\n",
              " ['maksssksksss0.png',\n",
              "  'maksssksksss1.png',\n",
              "  'maksssksksss2.png',\n",
              "  'maksssksksss3.png',\n",
              "  'maksssksksss4.png'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw6G-0EAq9ea",
        "outputId": "beefda41-50d4-49be-bb53-86e903930ee2"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10160, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 10160 (delta 1), reused 3 (delta 1), pack-reused 10154\u001b[K\n",
            "Receiving objects: 100% (10160/10160), 10.45 MiB | 25.24 MiB/s, done.\n",
            "Resolving deltas: 100% (7041/7041), done.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.42.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKjpAc1WrKT4",
        "outputId": "9dbaea16-4b14-4b80-b3d1-603c87a199ba"
      },
      "source": [
        "pwd = !pwd # ['/kaggle/working']\n",
        "pwd = pwd[0] + '/'\n",
        "\n",
        "dataset_path = pwd + 'datasets/facemask/'\n",
        "if not os.path.isdir(dataset_path):\n",
        "    !mkdir -p {dataset_path}\n",
        "\n",
        "new_images_path = dataset_path + 'images/'\n",
        "new_labels_path = dataset_path + 'labels/'\n",
        "\n",
        "if not os.path.isdir(new_images_path):\n",
        "    !cp -rf {images_path} {dataset_path}\n",
        "if not os.path.isdir(new_labels_path):\n",
        "    !mkdir -p {new_labels_path}\n",
        "!ls {dataset_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images\tlabels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJWT5dfPrSPB"
      },
      "source": [
        "def get_yolo_format(pic_width, pic_height, x_min, y_min, x_max, y_max):\n",
        "    x_center = (x_max + x_min) / (2 * pic_width)\n",
        "    y_center = (y_max + y_min) / (2 * pic_height)\n",
        "    width = (x_max - x_min) / pic_width\n",
        "    height = (y_max - y_min) / pic_height\n",
        "    return x_center, y_center, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbEO1zxircCR"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "labels = ['with_mask', 'mask_weared_incorrect', 'without_mask']\n",
        "infos = [] # used <5. Compare images>\n",
        "\n",
        "for annotations_file in annotations_files:\n",
        "    label_file_name = annotations_file.split('.')[0] + '.txt'\n",
        "    with open(new_labels_path + label_file_name, 'w') as label_file:\n",
        "        root = ET.parse(annotations_path + annotations_file)\n",
        "        pic_width = int(root.find('size').findtext('width'))\n",
        "        pic_height = int(root.find('size').findtext('height'))\n",
        "        info = [pic_width, pic_height]\n",
        "        for obj in root.findall('object'):\n",
        "            box_info = []\n",
        "            class_name = obj.findtext('name')\n",
        "            x_min = int(obj.find('bndbox').findtext('xmin'))\n",
        "            y_min = int(obj.find('bndbox').findtext('ymin'))\n",
        "            x_max = int(obj.find('bndbox').findtext('xmax'))\n",
        "            y_max = int(obj.find('bndbox').findtext('ymax'))\n",
        "            info.append([labels.index(class_name), x_min, y_min, x_max, y_max])\n",
        "            yolo_format = get_yolo_format(pic_width, pic_height, x_min, y_min, x_max, y_max)\n",
        "            label_file.write(str(labels.index(class_name)) + ' ' + ' '.join(map(str, yolo_format)) + '\\n')\n",
        "        infos.append(info)\n",
        "        label_file.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTmJlIEore4A"
      },
      "source": [
        "labels_files = [something for something in os.listdir(new_labels_path) if not os.path.isdir(new_labels_path + something)]\n",
        "labels_files.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7w5mpFbsmA8",
        "outputId": "888c1f9f-1ddf-47fc-9e6d-ad5c05b77afb"
      },
      "source": [
        "!cat {new_labels_path}{labels_files[0]}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0.18359375 0.337431693989071 0.05859375 0.10109289617486339\n",
            "0 0.4013671875 0.3333333333333333 0.080078125 0.12021857923497267\n",
            "2 0.6689453125 0.3155737704918033 0.068359375 0.13934426229508196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsiG89P6snJh",
        "outputId": "b359fb3a-95e6-4907-f060-fb85c4cf3aa0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "show_count = 5 # used <5. Compare images>\n",
        "images_train, images_else, labels_train, labels_else = train_test_split(images_files, labels_files, test_size = 0.2)\n",
        "images_val, images_test, labels_val, labels_test = train_test_split(images_else, labels_else, test_size = show_count / len(images_else))\n",
        "\n",
        "len(images_train), len(images_val), len(images_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(682, 166, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RENyz5hWsqgy"
      },
      "source": [
        "sub_directories = ['train/', 'val/', 'test/']\n",
        "for sub_directory in sub_directories:\n",
        "    if not os.path.isdir(new_images_path + sub_directory):\n",
        "        !mkdir {new_images_path}{sub_directory}\n",
        "    if not os.path.isdir(new_labels_path + sub_directory):\n",
        "        !mkdir {new_labels_path}{sub_directory}\n",
        "        \n",
        "# move from all data to train\n",
        "!mv {new_images_path}{images_files[0].split('.')[0][:-1]}* {new_images_path}train\n",
        "!mv {new_labels_path}{labels_files[0].split('.')[0][:-1]}* {new_labels_path}train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3eSo91Ls3MJ"
      },
      "source": [
        "def move_data(source_directory, source_files, target_directory):\n",
        "    for source_file in source_files:\n",
        "        !mv {source_directory}{source_file} {target_directory}{source_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vzDjf5BsvVi"
      },
      "source": [
        "images_files_list = [images_val, images_test]\n",
        "labels_files_list = [labels_val, labels_test]\n",
        "\n",
        "for images_files, labels_files, sub_directory in zip(images_files_list, labels_files_list, sub_directories[1:]):\n",
        "    move_data(new_images_path + sub_directories[0], images_files, new_images_path + sub_directory)\n",
        "    move_data(new_labels_path + sub_directories[0], labels_files, new_labels_path + sub_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oSWowPntDKq"
      },
      "source": [
        "import yaml\n",
        "\n",
        "yaml_file = pwd + 'config.yaml'\n",
        "\n",
        "yaml_data = dict(\n",
        "    path = new_images_path,\n",
        "    train = (new_images_path + sub_directories[0])[:-1],\n",
        "    val = (new_images_path + sub_directories[1])[:-1],\n",
        "    nc = len(labels),\n",
        "    names = labels\n",
        ")\n",
        "\n",
        "with open(yaml_file, 'w') as f:\n",
        "    yaml.dump(yaml_data, f, explicit_start = True, default_flow_style = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMfZfwpktHbL",
        "outputId": "4531f371-a169-4d18-8259-3fb2a0ebd1d4"
      },
      "source": [
        "%%writefile {yaml_file}\n",
        "\n",
        "path: /kaggle/working/datasets/facemask/images/\n",
        "train: /kaggle/working/datasets/facemask/images/train\n",
        "val: /kaggle/working/datasets/facemask/images/val\n",
        "nc: 3\n",
        "names: ['with_mask', 'mask_weared_incorrect', 'without_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/yolov5/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25olCSo5tKkX",
        "outputId": "18a7962a-08f9-44c9-f16d-3e210336b7f4"
      },
      "source": [
        "!cat config.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "path: /kaggle/working/datasets/facemask/images/\n",
            "train: /kaggle/working/datasets/facemask/images/train\n",
            "val: /kaggle/working/datasets/facemask/images/val\n",
            "nc: 3\n",
            "names: ['with_mask', 'mask_weared_incorrect', 'without_mask']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DktkxOmPtiiq",
        "outputId": "72f08728-ac4e-448c-93f3-1396adb1eab4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml\t detect.py   LICENSE\t       runs\t       utils\n",
            "CONTRIBUTING.md  Dockerfile  models\t       setup.cfg       val.py\n",
            "data\t\t export.py   README.md\t       train.py        yolov5\n",
            "datasets\t hubconf.py  requirements.txt  tutorial.ipynb  yolov5s.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovG1wKh0tOL4"
      },
      "source": [
        "yolo_path = 'yolov5/'\n",
        "if not os.path.isdir(yolo_path):\n",
        "    !git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip3 install -qr {yolo_path}requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UcoaLbQ9t3jS",
        "outputId": "24f80027-d574-4a35-bd8e-598c0266d035"
      },
      "source": [
        "import torch\n",
        "\n",
        "model_name = 'yolov5l'\n",
        "image_size = 640\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "device = '0' if torch.cuda.is_available() else 'cpu'\n",
        "saved_model_name = 'best.pt'\n",
        "\n",
        "# for test\n",
        "confidence_threshold = 0.25 # Threshold of object inference\n",
        "iou_threshold = 0.45 # Threshold of remove overlapping boxes\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7SVMnSguKWB"
      },
      "source": [
        "!python3 {yolo_path}train.py --weights {model_name}.pt \\\n",
        "        --cfg {yolo_path}models/{model_name}.yaml --data {yaml_file} \\\n",
        "        --hyp {yolo_path}data/hyps/hyp.scratch.yaml --epochs {epochs} --batch-size {batch_size} \\\n",
        "        --img-size {image_size} --device {device}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZT91618ymLh",
        "outputId": "96013702-336e-4137-fb90-6d14a2e6e375"
      },
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 10 --data coco128.yaml --weights yolov5s.pt --cache\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mteera\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.0-126-g3f152e5 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mblooming-bird-6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/teera/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/teera/YOLOv5/runs/ciefampl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20211207_170904-ciefampl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/datasets/facemask/labels/test' images and labels...853 found, 0 missing, 0 empty, 0 corrupted: 100% 853/853 [00:01<00:00, 537.84it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/datasets/facemask/labels/test.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB ram):  84% 719/853 [00:08<00:01, 80.11it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.7GB ram): 100% 853/853 [00:10<00:00, 80.06it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/datasets/facemask/labels/test.cache' images and labels... 853 found, 0 missing, 0 empty, 0 corrupted: 100% 853/853 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram):  53% 450/853 [00:06<00:05, 68.48it/s]libpng warning: iCCP: Not recognizing known sRGB profile that has been edited\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB ram): 100% 853/853 [00:11<00:00, 75.31it/s]\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.60 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/9     3.24G    0.1109   0.05456   0.03331        64       640: 100% 54/54 [01:03<00:00,  1.17s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:21<00:00,  1.28it/s]\n",
            "                 all        853       4072     0.0172     0.0464    0.00668    0.00123\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/9     5.87G   0.08663   0.06421   0.02329        55       640: 100% 54/54 [01:01<00:00,  1.14s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:22<00:00,  1.20it/s]\n",
            "                 all        853       4072      0.744      0.137     0.0624     0.0141\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/9     5.87G   0.06781   0.04963   0.02007        65       640: 100% 54/54 [01:01<00:00,  1.14s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:18<00:00,  1.48it/s]\n",
            "                 all        853       4072      0.849       0.19      0.208     0.0627\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       3/9     5.87G   0.06914    0.0441   0.01923        16       640: 100% 54/54 [01:00<00:00,  1.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:17<00:00,  1.58it/s]\n",
            "                 all        853       4072      0.836      0.203      0.202     0.0808\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       4/9     5.87G   0.06201   0.04014   0.01818        25       640: 100% 54/54 [01:00<00:00,  1.13s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:16<00:00,  1.61it/s]\n",
            "                 all        853       4072      0.523        0.4      0.266        0.1\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       5/9     5.87G   0.05515   0.03966   0.01676        62       640: 100% 54/54 [01:00<00:00,  1.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:16<00:00,  1.64it/s]\n",
            "                 all        853       4072       0.56      0.437      0.283     0.0772\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       6/9     5.87G   0.05154   0.03847   0.01561        62       640: 100% 54/54 [01:00<00:00,  1.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:16<00:00,  1.65it/s]\n",
            "                 all        853       4072      0.677      0.426      0.403       0.16\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       7/9     5.87G   0.04683    0.0388   0.01366        68       640: 100% 54/54 [01:00<00:00,  1.13s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:16<00:00,  1.67it/s]\n",
            "                 all        853       4072      0.826      0.519      0.547      0.265\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       8/9     5.87G   0.04243    0.0374   0.01196        19       640: 100% 54/54 [01:00<00:00,  1.13s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:15<00:00,  1.69it/s]\n",
            "                 all        853       4072      0.846      0.507      0.542       0.26\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       9/9     5.87G   0.04253    0.0364   0.01129        55       640: 100% 54/54 [01:00<00:00,  1.12s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:15<00:00,  1.69it/s]\n",
            "                 all        853       4072      0.911      0.524       0.58      0.309\n",
            "\n",
            "10 epochs completed in 0.224 hours.\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp3/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 27/27 [00:22<00:00,  1.21it/s]\n",
            "                 all        853       4072      0.911      0.524       0.58       0.31\n",
            "           with_mask        853       3232      0.874      0.889      0.917      0.532\n",
            "mask_weared_incorrect        853        123          1          0     0.0424     0.0236\n",
            "        without_mask        853        717      0.858      0.682       0.78      0.373\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4183... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▂▃▃▄▄▆███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▁▂▃▃▃▅▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▇█▇▅▅▆▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▂▃▃▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▆▄▄▃▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ▆█▄▃▂▂▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▆▄▄▃▄▂▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▆▅▅▄▄▃▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▆▄▃▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁▄▆▇██▆▅▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁▄▆▇██▆▅▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▇▇▆▅▄▃▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.57975\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.30922\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.91071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.52432\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.04253\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.01129\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.0364\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.03051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.02919\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00066\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00066\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.04676\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mblooming-bird-6\u001b[0m: \u001b[34mhttps://wandb.ai/teera/YOLOv5/runs/ciefampl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20211207_170904-ciefampl/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQIdGuI0Luy",
        "outputId": "b2fd9080-edd2-4c9b-832e-021ac076b863"
      },
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp3/weights/best.pt --img 640 --conf 0.25 --iou 0.45 --source test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp3/weights/best.pt'], source=test, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.0-126-g3f152e5 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/5 /content/yolov5/test/001.jpg: 640x640 5 with_masks, Done. (0.034s)\n",
            "image 2/5 /content/yolov5/test/002.jpg: 640x640 4 without_masks, Done. (0.034s)\n",
            "image 3/5 /content/yolov5/test/003.jpg: 640x640 8 with_masks, Done. (0.034s)\n",
            "image 4/5 /content/yolov5/test/004.jpg: 640x640 10 with_masks, 2 without_masks, Done. (0.034s)\n",
            "image 5/5 /content/yolov5/test/005.jpg: 640x640 2 with_masks, 1 without_mask, Done. (0.034s)\n",
            "Speed: 0.6ms pre-process, 33.9ms inference, 1.7ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2fvjro31D8l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}